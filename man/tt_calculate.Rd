% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/travel_time_matrix.R
\name{tt_calculate}
\alias{tt_calculate}
\title{Create a travel time matrix (batched + async)}
\usage{
tt_calculate(
  centroids,
  max_dist = 120000,
  routing_server = "http://127.0.0.1:5001/",
  profile = "car",
  n_concurrent = parallel::detectCores() * 3,
  n_batches = 100,
  max_url_coords = 200L,
  flush_every = 50000L,
  output_dir = NULL
)
}
\arguments{
\item{centroids}{<\code{sf}> Points with \code{id} column}

\item{max_dist}{<\code{numeric}> Max distance in meters for destination filtering}

\item{routing_server}{<\code{character}> OSRM server URL (must end with /)}

\item{profile}{<\code{character}> OSRM routing profile (driving, foot, bicycle)}

\item{n_concurrent}{<\code{integer}> Simultaneous HTTP requests. Optimal value is
roughly 3x the number of threads given to the OSRM container (e.g., 200 for
a 64-thread server). Beyond ~3x, throughput plateaus as OSRM becomes
CPU-bound. Too high may cause connection timeouts.}

\item{n_batches}{<\code{integer}> Number of spatial batches for neighbor indexing.}

\item{max_url_coords}{<\code{integer}> Max coordinates per OSRM request. Controls
URL length and matrix computation size. Testing showed:
\itemize{
\item 200: 100\% success, ~16k rows/sec on 28 threads (recommended default)
\item 500: 100\% success, similar throughput (larger matrices offset fewer requests)
\item 100: 100\% success but ~40\% slower due to HTTP overhead
Higher values reduce HTTP overhead but increase per-request OSRM computation
time (matrix calc is O(n²)). Values above 500 may timeout on slower servers.
}}

\item{flush_every}{<\code{integer}> Number of origins to process per flush cycle.
Controls peak memory: each cycle fetches, parses, writes to disk, then frees
memory. Lower values = less RAM but more disk I/O overhead. Default 50000 is
a good balance for most workloads.}

\item{output_dir}{<\code{character}|\code{NULL}> Directory for incremental output. If
provided, results are flushed to disk in batches as \code{.qs} files and the
function returns \code{invisible(output_dir)}. If \code{NULL} (default), all results
are held in memory and returned as a named list of \code{data.table}s. For large
jobs (>50k origins), always set \code{output_dir} to avoid OOM.}
}
\value{
Named list of data.tables, or invisible(output_dir) if writing to disk
}
\description{
Create a travel time matrix (batched + async)
}
\details{
\subsection{Performance tuning}{

The bottleneck is typically the OSRM server, not R. Key findings from benchmarking:
\itemize{
\item \strong{n_concurrent}: Throughput plateaus at ~3x OSRM threads. For a 28-thread
OSRM container, 100 concurrent requests saturates the server. Going higher
just queues requests without speed gain.
\item \strong{max_url_coords}: Trade-off between HTTP overhead and matrix computation.
200 coords/request is the sweet spot — small enough for fast OSRM response,
large enough to minimize request overhead. Requests are automatically chunked
if an origin has more neighbors than this limit.
}
}

\subsection{Memory management}{

With \code{output_dir} set, memory usage is bounded by \code{flush_every} origins at a
time. Each flush cycle: fetch → parse → write \code{.qs} → free. This prevents the
OOM kills that occur when millions of origin-destination pairs accumulate in
the \code{responses} environment and result lists simultaneously.
}
}
